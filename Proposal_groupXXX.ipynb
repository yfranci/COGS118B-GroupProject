{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lbjnlSj1ghF"
      },
      "source": [
        "# COGS 118B - Project Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgrkjZf11ghH"
      },
      "source": [
        "# Names\n",
        "\n",
        "- Youssef Franci\n",
        "- Jordan Nishi\n",
        "- Yash Singh\n",
        "- Michael Sherrick\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bt-obIw1ghH"
      },
      "source": [
        "# Abstract\n",
        "This project proposal outlines the development of an innovative dietary management system designed to assist individuals with dietary restrictions during their grocery shopping. With a focus on integrating advancements in object detection technology, nutritional analysis, and personalized dietary guidance, this system aims to provide real-time support for individuals navigating dietary challenges due to health conditions, allergies, or lifestyle choices. By leveraging deep learning algorithms for object detection, machine learning for nutritional content estimation, and unsupervised learning techniques for item categorization, the proposed system will enable users to identify food items, understand their nutritional content, and assess their compliance with specific dietary needs directly while shopping.\n",
        "\n",
        "The necessity for such a solution is underscored by the limitations of current technologies that often require manual input or offer generic advice, failing to provide real-time, personalized dietary support. The project will explore various data sources, including grocery sales data, food image datasets, and nutritional information databases, to build a comprehensive tool that offers OCR-based nutritional information extraction, accurate item identification, detailed nutritional analysis, and tailored dietary recommendations.\n",
        "\n",
        "Furthermore, the proposal addresses the challenges of ensuring data privacy, mitigating biases, and providing transparency in the application of machine learning algorithms. Through a combination of quantitative and qualitative evaluation metrics, including precision, recall, F1 score, and compliance rate with dietary restrictions, the project aims to validate the effectiveness and accuracy of the proposed system.\n",
        "\n",
        "This project not only seeks to bridge the gap in dietary management technologies but also emphasizes ethical and privacy considerations, ensuring a user-friendly, equitable, and privacy-conscious solution. By addressing the specific needs of individuals with dietary restrictions, this system aims to facilitate healthier food choices, enhance dietary compliance, and ultimately improve the quality of life for its users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Whv66jT1ghI"
      },
      "source": [
        "# Background\n",
        "\n",
        "In recent years, the intersection of technology and health has seen significant advancements, particularly in the development of tools aimed at enhancing dietary management and nutritional awareness. The prevalence of dietary restrictions due to health conditions such as diabetes, cardiovascular diseases, and allergies, along with lifestyle choices such as vegetarianism, has necessitated the innovation of personalized dietary assistance technologies. This project builds upon a foundation of research and development in object detection, nutritional analysis, and dietary compliance technologies, aiming to offer a novel solution for individuals navigating dietary restrictions.\n",
        "\n",
        "Object detection technology, a cornerstone of this project, has evolved rapidly with the advent of deep learning algorithms. Techniques such as Convolutional Neural Networks (CNNs) have been extensively applied in recognizing and classifying objects within images with high accuracy<a name=\"He\"></a>[<sup>[1]</sup>](#He). These advancements provide a robust framework for identifying fruits, vegetables, and packaged goods in real-time, a critical component of our proposed system.\n",
        "\n",
        "Parallel to object detection, significant work has been undertaken in the field of nutritional analysis. Studies have explored the use of image recognition and machine learning to estimate the nutritional content of foods from images, providing insights into calorie counts, macronutrient distributions, and micronutrient levels<a name=\"Meyers\"></a>[<sup>[2]</sup>](#Meyers). This research is vital for our project, as it enables the automatic assessment of the nutritional value of detected items.\n",
        "\n",
        "Furthermore, the development of applications that cater to specific dietary restrictions has seen growing interest. For instance, systems have been designed to assist individuals with diabetes by tracking blood glucose levels and recommending appropriate foods<a name=\"Smith\"></a>[<sup>[3]</sup>](#Smith). Similarly, apps targeting vegetarians and those with other dietary preferences have been developed to filter food choices based on set criteria<a name=\"Zhou\"></a>[<sup>[4]</sup>](#Zhou). These precedents highlight the feasibility and demand for dietary guidance technologies, underscoring the importance of our project's goal to integrate such functionalities into a comprehensive object detection and analysis system.\n",
        "\n",
        "Our project aims to synthesize these developments, creating an innovative system that not only recognizes and analyzes food items in grocery settings but also evaluates their compliance with user-defined dietary restrictions. By leveraging state-of-the-art object detection techniques, integrating advanced nutritional analysis algorithms, and incorporating user-specific dietary guidelines, our system will provide personalized recommendations, supporting individuals in making informed dietary choices during their grocery shopping.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnH06gtN1ghI"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "Despite the advancements in technology and healthcare, individuals with dietary restrictions continue to face significant challenges in managing their diets effectively, especially during grocery shopping. These challenges stem from the need to accurately identify food items, understand their nutritional content, and assess their compliance with specific dietary needs in real-time. Current solutions often require manual input of food items into applications or rely on generic dietary advice, lacking personalized guidance and real-time decision support. Furthermore, the existing technologies predominantly focus on either object detection, nutritional analysis, or dietary compliance in isolation, without offering an integrated solution that caters to the nuanced requirements of individuals with dietary restrictions such as diabetes, cardiovascular diseases, vegetarianism, or sodium intake limitations.\n",
        "\n",
        "The absence of a comprehensive, user-friendly system that combines real-time object detection and analysis with personalized dietary compliance assessment poses a significant barrier. It limits the ability of individuals with dietary restrictions to make informed, health-conscious decisions during their grocery shopping. Consequently, there is a pressing need for an innovative solution that leverages advancements in machine learning, image recognition, and nutritional science. This solution should not only recognize and analyze a wide range of fruits, vegetables, and grocery store items but also evaluate their suitability based on user-defined dietary restrictions, thereby providing actionable advice to facilitate healthier food choices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne_UIMfq1ghI"
      },
      "source": [
        "# Data\n",
        "\n",
        "Here is a list of potential but not restrictive or limited data sources we will be exploring in this project:\n",
        "1. Groceries Dataset\n",
        "    - Link/Reference: [Kaggle Groceries Dataset](https://www.kaggle.com/datasets/heeraldedhia/groceries-dataset#)\n",
        "    - Description: This dataset comprises sales data of groceries over a period from different customers. It includes thousands of observations with variables such as the date of purchase, customer ID, and item description.\n",
        "    - Observation Consists of: Each observation details a single item purchased, including the date, customer ID, and item name.\n",
        "    - Critical Variables: Item name (for object recognition), date (for temporal analysis), and customer ID (for purchasing patterns).\n",
        "    - Special Handling: Cleaning to remove duplicates, normalization of item names for consistent object detection.\n",
        "2. Nature Article's Food Dataset\n",
        "    - Link/Reference: [Nature Article's Dataset](https://www.nature.com/articles/s41597-020-0397-7)\n",
        "    - Description: This dataset is part of a study published in Nature, focusing on food images and their nutritional information. It's a rich dataset intended for image recognition and nutritional analysis.\n",
        "    - Observation Consists of: Images of food items along with detailed nutritional information.\n",
        "    - Critical Variables: Food images (for object detection), nutritional content (calories, fats, proteins, etc.).\n",
        "    - Special Handling: Image preprocessing (resizing, normalization), extraction of nutritional data for analysis.\n",
        "3. Food Nutrition Dataset\n",
        "    - Link/Reference: [Kaggle Food Nutrition Dataset](https://www.kaggle.com/datasets/shrutisaxena/food-nutrition-dataset)\n",
        "    - Description: Dataset providing nutritional information for various food items, including calories, fats, proteins, vitamins, and minerals.\n",
        "    - Observation Consists of: Food item name and its nutritional content.\n",
        "    - Critical Variables: Nutritional values (for assessing dietary compliance).\n",
        "    - Special Handling: Normalization of food item names for matching with object detection outputs, conversion of units if necessary.\n",
        "4. Dietary Behavior Dataset\n",
        "    - Link/Reference: [Dietary Behavior Dataset GitHub](https://github.com/CSSEHealthcare/Dietary-Behavior-Dataset?tab=readme-ov-file)\n",
        "    - Description: A dataset focusing on dietary behaviors and food intake, useful for understanding dietary restrictions and preferences.\n",
        "    - Observation Consists of: Entries related to dietary behaviors, food intake logs.\n",
        "    - Critical Variables: Types of foods consumed, dietary restrictions.\n",
        "   - Special Handling: Analysis of dietary patterns, identification of restriction-compliant foods.\n",
        "5. Food Nutrition Information\n",
        "    - Link/Reference: [Data.world Nutrition Information](https://data.world/adamhelsinger/food-nutrition-information)\n",
        "    - Description: This dataset provides comprehensive nutritional information for a wide range of food items.\n",
        "    - Observation Consists of: Food item names with detailed nutritional information.\n",
        "    - Critical Variables: Nutritional values (for detailed analysis).\n",
        "    - Special Handling: Data cleaning, normalization of food names, and integration with object detection outputs.\n",
        "6. Nutrition5k\n",
        "    - Link/Reference: [Nutrition5k GitHub](https://github.com/google-research-datasets/Nutrition5k)\n",
        "    - Description: A dataset from Google Research containing images of meals, their recipes, and nutritional information, aimed at connecting food visuals to their nutritional profiles.\n",
        "    - Observation Consists of: Meal images, recipes, nutritional data.\n",
        "    - Critical Variables: Meal images (for object detection), nutritional information (for analysis).\n",
        "    - Special Handling: Image preprocessing, extraction of nutritional data, matching recipes with detected items.\n",
        "7. Nutritional Values for Common Foods and Products\n",
        "    - Link/Reference: [Kaggle Nutritional Values Dataset](https://www.kaggle.com/datasets/trolukovich/nutritional-values-for-common-foods-and-products)\n",
        "    - Description: Provides nutritional information for a variety of foods and products, including calories, macronutrients, and micronutrients.\n",
        "    - Observation Consists of: Food items with their nutritional content.\n",
        "    - Critical Variables: Nutritional values.\n",
        "    - Special Handling: Data cleaning, categorization of foods, normalization for consistency with object detection results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrcBjSlY1ghJ"
      },
      "source": [
        "# Proposed Solution\n",
        "\n",
        "Our solution aims to address the challenges faced by individuals with dietary restrictions during grocery shopping by leveraging unsupervised machine learning techniques, OCR (Optical Character Recognition) technology, and a user-friendly interface. The goal is to develop an integrated system that not only identifies and categorizes grocery items but also analyzes their nutritional content and provides personalized dietary recommendations. Here's how we propose to achieve this:\n",
        "## Nutritional Information Extraction\n",
        "We will employ OCR technology to extract text from images of nutrition labels on food packaging. This process involves several steps of image preprocessing, such as adjusting contrast and brightness, to improve the visibility of the text and enhance the accuracy of the text extraction. The OCR-generated text data will then be parsed to identify and extract relevant nutritional information, such as calories, fats, proteins, vitamins, and minerals.\n",
        "## Item Identification and Categorization\n",
        "Using unsupervised learning algorithms, specifically clustering and topic modeling (e.g., LDA - Latent Dirichlet Allocation), we will analyze the descriptions of identified items to categorize them into appropriate food groups or nutritional categories. This step is crucial for understanding the variety of items a user purchases and for facilitating the subsequent nutritional analysis by grouping similar items together.\n",
        "## Nutritional Analysis\n",
        "Once items are categorized, we will cross-reference them with an extensive nutritional database to estimate their nutritional content. This analysis will provide detailed insights into the macronutrient and micronutrient profiles of the user's grocery items, enabling a comprehensive evaluation of their dietary intake.\n",
        "## Personalized Recommendation Engine\n",
        "Leveraging the data from the nutritional analysis, we will develop a recommendation engine that offers dietary suggestions tailored to the user's specific needs and restrictions. This engine will consider various dietary requirements, such as diabetes management, gluten-free, vegan, or vegetarian diets, and suggest healthier alternatives or adjustments to ensure a balanced and restriction-compliant diet. The recommendations will include information on missing nutrients and propose items that could enrich the user's dietary diversity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrN7aibV1ghJ"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "To effectively measure the performance and impact of the proposed dietary management system, we will employ a combination of quantitative and qualitative evaluation metrics. These metrics are chosen to reflect the system's accuracy, usability, and overall effectiveness in aiding users with dietary restrictions.\n",
        "## 1. Accuracy of Object Detection and Nutritional Analysis (Quantitative Metric)\n",
        "- Precision and Recall: Precision (the proportion of true positive results in all positive predictions) and Recall (the proportion of true positive results in all actual positives) will be used to evaluate the accuracy of object detection and nutritional analysis components. These metrics are crucial for ensuring that the system reliably identifies food items and accurately estimates their nutritional content.\n",
        "    - Precision = $\\frac{TP}{TP+FP}$\n",
        "    - Recall = $\\frac{TP}{TP+FN}$\n",
        "\n",
        "Where where $TP$ is true positives, $FP$ is false positives and FN is false negatives.\n",
        "\n",
        "- F1 Score: The F1 Score will be used to balance the precision and recall, providing a single metric to assess the overall accuracy of the system. It is particularly useful in scenarios where the balance between precision and recall is important.\n",
        "\n",
        "$F1=2\\times \\frac {Precision \\times Recall}{Precision + Recall}$\n",
        "\n",
        "\n",
        "## 2. Compliance Rate with Dietary Restrictions (Quantitative Metric)\n",
        "- Compliance Rate: This metric measures the proportion of recommended items that comply with the user's dietary restrictions out of all recommendations made.\n",
        "\n",
        "$\\text{Compliance Rate} = \\frac {\\text{Number of Compliant Recommendations}}{\\text{Total Number of Recommendationsâ€‹}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyjaU9lz1ghJ"
      },
      "source": [
        "# Ethics & Privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-bs1ciK1ghJ"
      },
      "source": [
        "Given the sensitivity of dietary preferences and the potential for personal health data involvement, our project must navigate several ethical and privacy concerns:\n",
        "\n",
        "1. Data Privacy and Consent: Ensuring the privacy of user data, especially when dealing with health-related information, is paramount. All data collection and processing will adhere to GDPR and other relevant privacy regulations. Users will be fully informed about what data is collected and how it is used, with explicit consent required.\n",
        "2. Bias and Fairness: Machine learning models can inadvertently perpetuate or amplify biases present in training data. We will actively work to identify and mitigate biases in our datasets, ensuring our system is fair and equitable across diverse user groups. This includes testing for biases in object recognition and nutritional analysis algorithms and adjusting models accordingly.\n",
        "3. Transparency and Explainability: It's important for users to understand how the system makes its recommendations. We will strive for transparency in our algorithms, providing users with clear explanations of how dietary recommendations are generated and why certain items are flagged as non-compliant with their dietary restrictions.\n",
        "4. Unintended Consequences: Recognizing that ML systems can have unintended consequences, we will establish mechanisms for continuous monitoring and feedback to identify and address any negative impacts. This includes setting up a system for users to report issues or concerns and regularly reviewing system performance and user feedback.\n",
        "5. Addressing Ethical Concerns: To systematically address these and other potential ethical concerns, we will utilize ethical frameworks and tools such as the Ethics and Governance of AI Initiative's toolkit. This will help in identifying, assessing, and mitigating ethical risks at various stages of the project lifecycle.\n",
        "6. Continuous Ethical Review: Recognizing that ethical considerations evolve over time, we will commit to regular ethical reviews of our project. This includes revisiting our data handling practices, algorithms, and user feedback mechanisms to ensure they remain aligned with ethical standards and user expectations.\n",
        "\n",
        "By proactively addressing these ethical and privacy concerns, we aim to build a system that not only enhances the grocery shopping experience for individuals with dietary restrictions but also respects and protects their privacy and rights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgDcrUUX1ghK"
      },
      "source": [
        "# Team Expectations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of1i8TJK1ghK"
      },
      "source": [
        "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
        "* *Team Expectation 1:* work will be evenly divided amongst all team members, no one person will have to do more work than the other\n",
        "* *Team Expectation 2:* we will all communicate effectively on the platform discussed (in our case, the groupchat on messages)\n",
        "* *Team Expecation 3:* All work will be completed by the time discussed and set by the group\n",
        "* *Team Expecation 4:* All conflict will be resolved in a civil and amicable manner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajRxJPI41ghK"
      },
      "source": [
        "# Project Timeline Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl1i39BX1ghK"
      },
      "source": [
        "| Completion Date  | Task | Notes |\n",
        "|---|---|---|\n",
        "| 2/28  |  Proposal |  Final due date for proposal (delayed for group organization)  |\n",
        "| 3/2 | Data cleaning | Clean/Augment (if necessary)/Format for model training |\n",
        "| 3/6 | Model Testing | Initial experimentation with models (comparing architectures/training methods/inference latency) |\n",
        "| 3/9 | Final Model Choice/Training | Select model to be used & perform final training/evaluations |\n",
        "| 3/13  | Nutrition Analysis  | Finalize integration of model prediction with nutrition information |\n",
        "| 3/16  | Personal Recommendations  | Restrict nutrition information to correspond to user's preferences/requirements |\n",
        "| 3/20  | Turn in finalized project | N/A |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlEMwvxe1ghK"
      },
      "source": [
        "# Footnotes\n",
        "<a name=\"He\"></a>1.[^](#He):  He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 770-778.<br>\n",
        "<a name=\"Meyers\"></a>2.[^](#Meyers):  Meyers, A., Johnston, N., Rathod, V., Huang, A., Korattikara, A., Gorban, A., Silberman, N., Guadarrama, S., & Papandreou, G. (2015). Im2Calories: Towards an Automated Mobile Vision Food Diary. Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, 427-434.<br>\n",
        "<a name=\"Smith\"></a>3.[^](#Smith):  Smith, J. D., Suto, M. J., & Lee, H. (2017). Mobile Application for Diabetes Control: A Systematic Review and Meta-Analysis. Diabetes Technology & Therapeutics, 19(1), 1-9.<br>\n",
        "<a name=\"Zhou\"></a>4.[^](#Zhou): Zhou, L., Bao, J., Setiawan, I. M. A., Saptono, A., & Parmanto, B. (2018). The mHealth App Usability Questionnaire (MAUQ): Development and Validation Study. JMIR mHealth and uHealth, 6(4), e148.<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VFVuP_k1ghK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}